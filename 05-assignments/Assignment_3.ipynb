{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc88d9c-1760-4e18-a6c6-3ed1fc003b4b",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f307d-c76d-4cf9-95fc-76fc8008754e",
   "metadata": {},
   "source": [
    "This assignment is due on __Saturday March 23, by 11:59PM__. It pertains to content taught in classes 3-4-5.\n",
    "\n",
    "This assignment should be completed in Python, and a PDF file should be submitted, containing both code and written answers. If you like, you may create your own Jupyter Notebook file from scratch, but it is likely easier to modify this one.\n",
    "\n",
    "As before, questions that require identification and/or interpretation will not penalized for brevity of response: if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "If you like, you may collaborate with others in the class. If you choose to do so, please indicate with whom you have worked at the top of your PDF. Separate submissions are required.\n",
    "\n",
    "Any questions can be addressed to Kamilah ([kamilah.ebrahim@mail.utoronto.ca]()) and/or Ananya ([ananya.jha@mail.utoronto.ca]()) and/or Vishnou ([vishnouvina@cs.toronto.edu]()) before the due-date. Please submit your assignments through your Drive Folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8581ec-525b-4064-a3ef-5e1d48eecac5",
   "metadata": {},
   "source": [
    "### Question 1: Data cleaning and visualization\n",
    "\n",
    "For this assignment, we'll use the in-built dataset `credit` from `ISLP` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24439fb0-76bd-4ba8-9bc9-24c581704600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "     import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "\n",
    "# Load dataset\n",
    "my_df = load_data('credit')\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cc497-a66f-46a3-9658-88d34e7f232c",
   "metadata": {},
   "source": [
    "Before modeling, it's essential to \"get a feel\" for our data. Use the `credit?` function to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fac7d-6b95-47ac-955f-6d722b60ccff",
   "metadata": {},
   "source": [
    "_(i)_ How many variables (columns) are there?  \n",
    "\n",
    "_(ii)_ How many observations (rows) are there?  \n",
    "\n",
    "_(iii)_ How many factor variables are there?  \n",
    "\n",
    "_(iv)_ What are the factor labels (English) and levels (value) of the `Married` variable?\n",
    "\n",
    "_(v)_ What is the range of the `Cards` variable?\n",
    "\n",
    "_(vi)_  It is very important to understand if our data has missing values, which R represents as `NA`. Below, show that there are 0 NA values in the dataset. (Hint: you can use the function `np.isnan()` to search for `NA` values, and wrap that with the `sum()` function, to provide a total count.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fc55b-5608-4599-9ef8-df74efc3509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794af5f-2115-4bd9-bf75-944924fdd74d",
   "metadata": {},
   "source": [
    "It is also very important to visualize our data before modeling. The `sns.pairplot()` function visualizes the pair-wise correlations between all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331bacf-fe81-4e18-95a8-78296d58f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = my_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a scatterplot matrix\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f76224-6e55-4b21-907d-c8cb5761833a",
   "metadata": {},
   "source": [
    "_(vii)_ Which variable pair looks as if it has the strongest correlation?    \n",
    "\n",
    "_(viii)_ Name a variable pair that looks as though it has no/little correlation (many correct answers).   \n",
    "\n",
    "_(ix)_  Why do correlation pairs including the `Region` variable have three columns/rows of points?    \n",
    "\n",
    "_(x)_  For much of our modelling, we'll make use of a separate training and testing set. Choose your favourite method to split `my_df` into equally-sized training and testing sets. For clarity, call your training set `train`, and your testing set `test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e06904-8db4-41f8-90ef-7c95cffb5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1237f-7528-4a66-8583-71d0562fa04d",
   "metadata": {},
   "source": [
    "Congrats! Now that our data is familiar and 'clean', let's turn to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ddb4d3-f622-441f-90a9-46e2b7da479b",
   "metadata": {},
   "source": [
    "### Question 2: Regularization via Shrinkage\n",
    "\n",
    "Shrinkage methods can \"extend\" or improve upon linear model fits, by pushing coefficients towards (ridge regression) or to zero (lasso), and thus reducing variance. Let's perform ridge regression, using the `skl.ElasticNet()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed7c1f-0967-4822-8c47-7475f2c130cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dd538-a321-41b1-9c33-987a29311abf",
   "metadata": {},
   "source": [
    "Use our `my_df` dataset (deriving from Credit). Let's use `Balance` as the response variable, and all other variables as predictors. \n",
    "\n",
    "_(i)_ A necessary first step is to get our data into the format expected. Specifically, we must provide predictor variables in a matrix, and the response variable in a vector. For clarity, call the predictor matrix `x`, and the response vector `y`. (Hint: your `x` matrix should have should 400 rows and 11 columns. Verify that this is true, using in-built functions of your choice).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72023490-4fc2-4740-ac03-393b0236645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix of the predictor variables \n",
    "\n",
    "# create a vector of the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767e8a0-4e1f-4741-b4f2-ac56b74ea761",
   "metadata": {},
   "source": [
    "Let's check out how `ModelSpec()` has transformed our data. Compare the names of variables in our matrix `x`, compared to `my_df` (hint: use the `columns` function), and answer:\n",
    "\n",
    "_(ii)_ Which \"type\" of variables (numeric, character, factor, etc.) have a new name in `x`?  \n",
    "\n",
    "_(iii)_ Which variable in `x` has two columns dedicated to it? Why? \n",
    "\n",
    "_(iv)_ What variable in `my_df` is missing in x? Why might this be?    \n",
    "\n",
    "Now that we understand how our data is represented, we can move on to modelling. Fit a ridge regression model, using `skl.ElasticNet()`. (Hint: remember to set the alpha value!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92b4fe-8ad6-47ae-86ee-ee58cca9e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47136155-4a1d-48a3-bbc9-14d78996c78e",
   "metadata": {},
   "source": [
    "_(v)_ An essential part of ridge regression (and shrinkage methods more broadly) is to identify an 'ideal' lambda value. Use the appropriate function from `sk.learn` to identify this lambda value via cross-validation. (Hint: remember that `x` and `y` should not consist of the complete dataset!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c41a7-fa92-45fd-b4ce-94c9b116b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c043154-6c23-4eea-87dd-2c0fffd78f4e",
   "metadata": {},
   "source": [
    "_(vi)_ By default, cross validation via `skl.ElasticNet()` considers n=100 lambda values. The cross-validated model object that you created in the step above stores these n=100 lambda values within it. Print them here (Hint: use the `$` to \"look inside\" your model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058a4d6-38f3-4b00-be5d-7f376ae80973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2547e82-ab98-4b6c-ba21-49c369293b34",
   "metadata": {},
   "source": [
    "_(vii)_ Visualize your cross-validation results using `plot`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d35608-cba4-40b6-bad9-946cbb08a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c805e7-c735-4f78-b4ca-1226b4e5a127",
   "metadata": {},
   "source": [
    "_(viii)_ Now, look inside your cross-validated object to pull out the lambda value with the smallest error (Hint: the value will be that shown by the first, left-most vertical dotted line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669aa75-70ac-46b7-9e7b-51b0619ea559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2133e2e7-8adc-4a95-8a3b-8f3621845f17",
   "metadata": {},
   "source": [
    "_(ix)_ In your plot, what does the second (right-most) vertical dotted represent? (Hint: read the help documentation pertaining to `l1_ratio=0`.). \n",
    "\n",
    "_(x)_ We can now refit ridge regression, for the entire dataset, with the ideal lambda value. Use the lambda value with the smallest error. Provide an argument to print the estimated coefficients (Hint: check out the `type` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5891b-1389-4f78-944c-d258cea5da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d62d7-d98d-47ac-9a7d-3ad4eee43ac8",
   "metadata": {},
   "source": [
    "_(xi)_ Did you expect any coefficients to be exactly 0? Why or why not?  \n",
    "\n",
    "_(xii)_ The plot created above shows that the ideal 'tuning' (penalty) provided by lambda is comparatively small (one of the smallest considered by `skl.ElasticNet()`, if not the smallest). What might this suggest? In your answer, consider the nature of the `Credit` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b0be9-cbac-4d21-9702-9072995ed5bc",
   "metadata": {},
   "source": [
    "### Question 3: Decision (regression) tree\n",
    "\n",
    "Decision trees partition a dataset into smaller subgroups, and then fit a constant for every observation in a given subgroup. This method is well-able to model non-linear associations, and can be helpfully visualized.\n",
    "\n",
    "Let's continue to work with `my_df` (deriving from the `Credit` dataset). We will use the `tree` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e215907-c054-47bc-a5eb-956d0b5e8bac",
   "metadata": {},
   "source": [
    "_(i)_ Below, fit a tree in the training set. Use `Balance` as the response variable, and all other variables as predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebde71-e4ed-4e91-b481-83a9fb15b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c457e-608e-4075-a959-c93bd4bce71d",
   "metadata": {},
   "source": [
    "_(ii)_ Plot your tree, with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc8ee4-9a9d-406b-a180-d47ab1bc816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66602c-940a-4569-bf2f-2f5eb24edacc",
   "metadata": {},
   "source": [
    "Review the plot and/or the model `summary` to answer the following questions:\n",
    "\n",
    "_(iii)_ What is the most important variable for predicting `Balance` (Hint: what variable is at the top of the tree, i.e., the \"root\")?  \n",
    "\n",
    "_(iv)_ How many terminal nodes (\"leafs\") are there?\n",
    "\n",
    "_(v)_ What is the tree's error? (Hint: Look for `Residual mean deviance`)\n",
    "\n",
    "_(vi)_ Imagine an individual with the following characteristics: A `Limit` of $1000, and a `Rating` of 100. What would you predict their `Balance` to be?  \n",
    "\n",
    "In a sentence or two, answer the following conceptual questions about regression trees:\n",
    "\n",
    "_(vii)_ Regression trees are created via \"recursive binary splitting\". Why do we call recursive binary splitting a \"top down\", or \"greedy\", approach?  \n",
    "\n",
    "_(viii)_ Why is \"greediness\" required?  \n",
    "\n",
    "_(ix)_ We often \"cut\" a tree when a given terminal node (\"leaf\") has fewer than some fixed number of observations (e.g., n=5). Why is this?  \n",
    "\n",
    "_(x)_ Next, let's determine if our tree would benefit from \"pruning\". Below, call the appropriate cross-validation function on our tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0da391-8765-4609-8fa7-8b8f0f5aea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26766c-5219-4da6-82c0-c2ffd3a85932",
   "metadata": {},
   "source": [
    "_(xi)_ Plot the cross-validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233877c-ecd0-4a27-8125-7fe76ea13731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9a127-c653-49b3-9ca3-49a59f869e19",
   "metadata": {},
   "source": [
    "_(xii)_ The cross-validation function operates via k-fold. Review the help documentation this function. How many folds are fit by default?\n",
    "\n",
    "_(xiii)_ Does this tree require pruning? How do you know?\n",
    "\n",
    "Decision trees are often unstable (i.e., they greatly reflect the particular sample upon which they were created; this limitation motivates \"ensemble methods\", including random forest). \n",
    "\n",
    "_(xiv)_ If we were to fit the same tree model but in a new random sample, where would you expect to see the most variability: the top decision node (\"root\"), or the terminal nodes (\"leafs\")? Why? (You can test this if you like, but code is not required.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78903bd-b71b-480c-b24a-529c67fe68ed",
   "metadata": {},
   "source": [
    "### Bonus Question: Polynomial regression\n",
    "\n",
    "Let's again work with our `my_df`. Again, let's use `Balance` as the response variable, but this time, for ease, let's use only a single variable `Age` as a predictor. \n",
    "\n",
    "_(i)_ Fit four models: polynomial models with orders 2, 3, and 4, respectively, as well as the linear model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923012e-cbad-44fc-96a2-c5d46c906896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0eb84b-1070-47d6-bde1-332e8196c449",
   "metadata": {},
   "source": [
    "_(ii)_ We will compare these four models, to see which provides the better fit. What is the null hypothesis, $H_0$? What is the alternative hypothesis, $H_1$? \n",
    "\n",
    "_(iii)_ Compare these four models, using ANOVA. (Hint: remember, models must be entered in order of complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442de08c-5053-4051-a2f1-62af5aaa74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b57c79-402d-4f97-a33e-4ec789b10b86",
   "metadata": {},
   "source": [
    "_(iv)_ Based on the ANOVA results, can we reject the null hypothesis?  \n",
    "\n",
    "_(v)_ Based on the ANOVA results, which model do we say is best?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a3c64-06e8-4003-aca1-58ef0abc7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
